{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b75c4cd-4a52-4fa2-9c4a-df344db6b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install tensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, layers\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#from tensorflow.keras.models import Sequential\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# for data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from tensorflow.keras.models import load_modelfrom \n",
    "#from tensorflow.keras.utils import to_categoricaltensorflow.keras.callbacks import EarlyStopping\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0961-b61b-45ca-ba0e-8d17549c33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess CIFAR-10 data\n",
    "(train_images, train_labels), (testing_images, testing_labels) = cifar10.load_data()\n",
    "\n",
    "# 40k training\n",
    "# 10k validating\n",
    "# 10k testing\n",
    "# Further split training set into training and validation sets\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "# test_size=0.2 is the proportion of the dataset to be used for validation set\n",
    "# random_state=42 the split will always produce the same subsets of training and validation data\n",
    "# ensuring consistency in your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfe392-6076-4dcd-88f7-4212b832750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image data to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "validation_images = validation_images.astype('float32') / 255.0\n",
    "testing_images = testing_images.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8c6a2-b484-4106-8845-ec88c15b1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=4,          # Stop training if val_loss doesn't improve for 3 consecutive epochs\n",
    "    restore_best_weights=True  # Restore weights from the epoch with the best val_loss\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model2.keras',  # Save the best model to a file\n",
    "    monitor='val_loss',       # Save the model with the lowest validation loss\n",
    "    save_best_only=True       # Only save when there's an improvement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be8177-fcb5-44c4-bed8-4e4fcdbfb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    #brightness_range=[0.9, 1.1],\n",
    "    #shear_range=0.1, # distorting the image on an axes\n",
    "    #zoom_range=0.1,\n",
    "    #fill_mode='nearest', # filling the extra pixels using nearest neighbor\n",
    "    #channel_shift_range=5.0 # colos playing\n",
    ")\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b5f4f-4dcf-44be-986a-81d21a2282c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "input_shape = (32, 32, 3)\n",
    "model2 = models.Sequential()\n",
    "\n",
    "# convolutional layers with Batch Normalization\n",
    "model2.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# a dropout layer for regularization\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "# Flatten and fully connected layers\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "# Output layer for 10 classes\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b30b3-d6e2-42a1-9d67-d91f3fe7f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA SET 1st RUN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model2.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=40, # EARLY_STOPPING WILL DEAL WITH OVERFITTING\n",
    "    validation_data=(validation_images, validation_labels),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "# Print the epoch where training stopped\n",
    "print(f\"Training stopped at epoch {len(history.history['loss'])}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Extract accuracy and loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372435a1-f157-471f-967a-00919f7c27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "test_loss, test_accuracy = model2.evaluate(testing_images, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf684c-c6b0-4831-9d9d-dbc9587bb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy/loss\n",
    "epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_accuracy, color='orange', label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, val_accuracy, color='purple', label='Validation Accuracy', marker='o')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_loss, color='orange', label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, color='purple', label='Validation Loss', marker='o')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184d7a2-2760-4ea1-9e50-6d130cf78801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine earlystopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=4,          # Stop training if val_loss doesn't improve for 3 consecutive epochs\n",
    "    restore_best_weights=True  # Restore weights from the epoch with the best val_loss\n",
    ")\n",
    "\n",
    "# TRAINING DATA SET 2nd RUN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model2.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=20, # EARLY_STOPPING WILL DEAL WITH OVERFITTING\n",
    "    validation_data=(validation_images, validation_labels),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "# Print the epoch where training stopped\n",
    "print(f\"Training stopped at epoch {len(history.history['loss'])}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Extract accuracy and loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba7117-e75e-4bc3-b85e-097a18c0e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "test_loss, test_accuracy = model2.evaluate(testing_images, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a43e9-2378-46fa-b911-b18993b4bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy/loss\n",
    "epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_accuracy, color='orange', label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, val_accuracy, color='purple', label='Validation Accuracy', marker='o')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_loss, color='orange', label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, color='purple', label='Validation Loss', marker='o')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d63db5-0eff-4b36-a41b-a81d23b2ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine earlystopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=4,          # Stop training if val_loss doesn't improve for 3 consecutive epochs\n",
    "    restore_best_weights=True  # Restore weights from the epoch with the best val_loss\n",
    ")\n",
    "\n",
    "# AUGMENTED TRAINING DATA SET 1st RUN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# using the augmented images-data set\n",
    "history = model2.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=50, # EARLY_STOPPING WILL DEAL WITH OVERFITTING\n",
    "    validation_data=(validation_images, validation_labels),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "# Print the epoch where training stopped\n",
    "print(f\"Training stopped at epoch {len(history.history['loss'])}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Extract accuracy and loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d584e6-642d-4846-9135-c6462472782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "test_loss, test_accuracy = model2.evaluate(testing_images, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7c403-41b7-4ab9-9478-64ac79b5e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy/loss\n",
    "epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_accuracy, color='orange', label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, val_accuracy, color='purple', label='Validation Accuracy', marker='o')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid()\n",
    "plt.plot(epochs, train_loss, color='orange', label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, color='purple', label='Validation Loss', marker='o')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
